{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_item_count = 24\n",
    "rarity_thershold = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethem\\AppData\\Local\\Temp\\ipykernel_16776\\896890968.py:4: DtypeWarning: Columns (11,12,13,14,15,16,17,18,19,20,21,22,23,24,59,60,61,62,63,64,65,66,67,68,69,70,71,72,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,102,103,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(csv_file_path_train)\n",
      "C:\\Users\\ethem\\AppData\\Local\\Temp\\ipykernel_16776\\896890968.py:5: DtypeWarning: Columns (97,105,107,108,109,110,111,112,113,114,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(csv_file_path_test)\n"
     ]
    }
   ],
   "source": [
    "csv_file_path_train = './train_dataset.csv'\n",
    "csv_file_path_test = './submission_data_x.csv'\n",
    "\n",
    "df_train = pd.read_csv(csv_file_path_train)\n",
    "df_test = pd.read_csv(csv_file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethem\\AppData\\Local\\Temp\\ipykernel_16776\\222863778.py:1: DtypeWarning: Columns (11,12,13,14,15,16,17,18,19,20,21,22,23,24,59,60,61,62,63,64,65,66,67,68,69,70,71,72,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,102,103,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(csv_file_path_train)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(csv_file_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage the TEST data\n",
    "col_list = [\"item\", \"make\", \"model\", \"goods_code\"]\n",
    "all_colmns_to_append = []\n",
    "for clmn_name in col_list:\n",
    "\n",
    "    # Extract uniqueness and repetiteveness\n",
    "    row_count = df_test.shape[0]\n",
    "    count_dict = defaultdict(int)\n",
    "    \n",
    "    cols = {clmn_name+str(i) for i in range(1,max_item_count+1)}\n",
    "\n",
    "    for col in cols:\n",
    "        column_values = df_test[col]\n",
    "        # del df_test[col]\n",
    "        for row in range(row_count - 1):\n",
    "            item = column_values[row]\n",
    "            if pd.notna(item):\n",
    "                count_dict[str(item)] += 1\n",
    "\n",
    "    count_dict = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # ADD COLUMNS  \n",
    "    for key, count in count_dict:\n",
    "        if count > rarity_thershold:\n",
    "            all_colmns_to_append.append(str(key))\n",
    "\n",
    "all_colmns_to_append = list(set(all_colmns_to_append))\n",
    "new_data = pd.DataFrame(0, index=df_test.index, columns=all_colmns_to_append)\n",
    "df_test = pd.concat([df_test, new_data], axis=1)\n",
    "\n",
    "for clmn_name in col_list:\n",
    "    cols = {clmn_name+str(i) for i in range(1,max_item_count+1)}\n",
    "    # FILL NEWLY ADDED COLUMNS\n",
    "    for index, row in df_test.iterrows():\n",
    "        for col in cols:\n",
    "            cell = row[col]\n",
    "            if not pd.notna(cell):\n",
    "                break\n",
    "            if cell in df_test.columns:\n",
    "                df_test.at[index, cell] = 1\n",
    "\n",
    "    # DROP OLD COLUMNS\n",
    "    for col in cols:\n",
    "        del df_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage the TRAIN data\n",
    "\n",
    "# ADD COLUMNS\n",
    "cols_df_test = list(df_test.columns)\n",
    "cols_df_train = list(df_train.columns)\n",
    "cols_add_train = []\n",
    "\n",
    "for col in cols_df_test:\n",
    "    if col not in cols_df_train:\n",
    "        cols_add_train.append(col)\n",
    "\n",
    "new_data = pd.DataFrame(0, index=df_train.index, columns=cols_add_train)\n",
    "df_train = pd.concat([df_train, new_data], axis=1)\n",
    "\n",
    "for clmn_name in col_list:\n",
    "\n",
    "    cols = {clmn_name+str(i) for i in range(1,max_item_count+1)}\n",
    "\n",
    "    # # FILL NEWLY ADDED COLUMNS\n",
    "    for index, row in df_train.iterrows():\n",
    "        for col in cols:\n",
    "            cell = row[col]\n",
    "            if not pd.notna(cell):\n",
    "                break\n",
    "            if cell in df_train.columns:\n",
    "                df_train.at[index, cell] = 1\n",
    "\n",
    "    # DROP OLD COLUMNS\n",
    "    for col in cols:\n",
    "        del df_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# train_x ve train_y'yi yeniden tanımla (karıştırılmış df_train'den sonra)\n",
    "train_y = df_train['fraud_flag']\n",
    "train_x = df_train.drop(columns=['fraud_flag'])\n",
    "\n",
    "# %20'sini yeni bir test seti olarak ayır\n",
    "X_train, X_new_test, y_train, y_new_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Precision Score: 0.18594022900214496\n",
      "XGBoost Average Precision Score: 0.2148908889745039\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_new_test_probabilities = rf_model.predict_proba(X_new_test)[:, 1]\n",
    "\n",
    "# XGBoost modeli\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_new_test_probabilities = xgb_model.predict_proba(X_new_test)[:, 1]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({'Actual': y_new_test, \n",
    "                           'RF_Predicted_Probability': rf_new_test_probabilities,\n",
    "                           'XGB_Predicted_Probability': xgb_new_test_probabilities})\n",
    "\n",
    "# Sonuçları bir dosyaya yaz\n",
    "results_df.to_csv('new_test_results.txt', index=False, sep='\\t')\n",
    "\n",
    "# RandomForestClassifier için average precision score hesapla\n",
    "rf_average_precision = average_precision_score(results_df['Actual'], results_df['RF_Predicted_Probability'])\n",
    "print(f\"Random Forest Average Precision Score: {rf_average_precision}\")\n",
    "\n",
    "# XGBoost için average precision score hesapla\n",
    "xgb_average_precision = average_precision_score(results_df['Actual'], results_df['XGB_Predicted_Probability'])\n",
    "print(f\"XGBoost Average Precision Score: {xgb_average_precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Average Precision Score: 0.2355289369051183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Voting Classifier oluştur\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('random_forest', rf_model),\n",
    "    ('xgboost', xgb_model)\n",
    "], voting='soft')  # 'soft' oylama, sınıf olasılıklarının ortalamasını alır\n",
    "\n",
    "# Voting Classifier'ı eğit\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Voting Classifier'ın tahminlerini al\n",
    "voting_new_test_probabilities = voting_clf.predict_proba(X_new_test)[:, 1]\n",
    "\n",
    "# Voting Classifier için average precision score hesapla\n",
    "voting_average_precision = average_precision_score(y_new_test, voting_new_test_probabilities)\n",
    "print(f\"Voting Classifier Average Precision Score: {voting_average_precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_new_test_probabilities=voting_clf.predict_proba(df_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin olasılıklarını prediction.txt dosyasına yaz\n",
    "with open(\"sample_submission.csv\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Olasılık değerlerini içeren bir liste olduğunu varsayalım\n",
    "# Örneğin:\n",
    "# fraud_proba = [0.08, 0.0, 0.003333333333333333, 0.00030535604963342346, 0.0, ...]\n",
    "\n",
    "# Dosyanın sonuna olasılık değerlerini ekleyerek yeni bir liste oluştur\n",
    "new_lines = []\n",
    "for i, prob in enumerate(xgb_new_test_probabilities):\n",
    "    new_lines.append(f\"{lines[i + 1].strip()}{prob}\\n\")  # İlk satır başlık olduğu için 1'den başlayalım\n",
    "\n",
    "# Yeni satırları dosyaya yaz\n",
    "with open(\"voting.csv\", \"w\") as file:\n",
    "    file.write(\"ID,fraud_flag\\n\")  # Başlık satırını yaz\n",
    "    file.writelines(new_lines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
